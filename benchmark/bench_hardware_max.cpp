/**
 * HARDWARE MAXIMUM - Multi-threaded parallel benchmark
 * Target: 259+ GB/s (90% of 288 GB/s realistic max)
 *
 * Strategy:
 * - Use ALL 16 threads (8 cores + SMT)
 * - Each thread runs independent serialize operations
 * - 32x loop unrolling (2048 bytes/iteration)
 * - Non-temporal stores for cache bypass
 * - CPU affinity for thread pinning
 */

#include <immintrin.h>
#include <chrono>
#include <iostream>
#include <iomanip>
#include <vector>
#include <thread>
#include <atomic>
#include <cstdlib>
#include <cstdint>

using namespace std::chrono;

// Global atomic counter for synchronization
std::atomic<bool> start_flag{false};
std::atomic<int> ready_count{0};

// Per-thread result storage
struct ThreadResult {
    double gbps;
    uint64_t operations;
};

// Parallel serialize benchmark - each thread works independently
void thread_benchmark(int thread_id, size_t num_elements, size_t iterations, ThreadResult* result) {
    const size_t data_bytes = num_elements * sizeof(uint64_t);

    // Allocate thread-local buffers (aligned)
    uint64_t* data = (uint64_t*)aligned_alloc(64, data_bytes);
    uint8_t* buf = (uint8_t*)aligned_alloc(64, data_bytes + 64);

    // Initialize data
    for (size_t i = 0; i < num_elements; ++i) {
        data[i] = 0xABCDEF0123456789ULL ^ thread_id;
    }

    // Signal ready and wait for start
    ready_count.fetch_add(1);
    while (!start_flag.load(std::memory_order_acquire)) {
        std::this_thread::yield();
    }

    // Warmup
    for (size_t i = 0; i < 100; ++i) {
        *reinterpret_cast<uint64_t*>(buf) = num_elements;
        const __m512i* s = (const __m512i*)data;
        __m512i* d = (__m512i*)(buf + 8);

        // 32x unrolling - 2048 bytes per iteration
        for (size_t j = 0; j < data_bytes/64; j += 32) {
            // Load 32 x 64-byte chunks
            __m512i v0 = _mm512_load_si512(s+j);
            __m512i v1 = _mm512_load_si512(s+j+1);
            __m512i v2 = _mm512_load_si512(s+j+2);
            __m512i v3 = _mm512_load_si512(s+j+3);
            __m512i v4 = _mm512_load_si512(s+j+4);
            __m512i v5 = _mm512_load_si512(s+j+5);
            __m512i v6 = _mm512_load_si512(s+j+6);
            __m512i v7 = _mm512_load_si512(s+j+7);
            __m512i v8 = _mm512_load_si512(s+j+8);
            __m512i v9 = _mm512_load_si512(s+j+9);
            __m512i v10 = _mm512_load_si512(s+j+10);
            __m512i v11 = _mm512_load_si512(s+j+11);
            __m512i v12 = _mm512_load_si512(s+j+12);
            __m512i v13 = _mm512_load_si512(s+j+13);
            __m512i v14 = _mm512_load_si512(s+j+14);
            __m512i v15 = _mm512_load_si512(s+j+15);
            __m512i v16 = _mm512_load_si512(s+j+16);
            __m512i v17 = _mm512_load_si512(s+j+17);
            __m512i v18 = _mm512_load_si512(s+j+18);
            __m512i v19 = _mm512_load_si512(s+j+19);
            __m512i v20 = _mm512_load_si512(s+j+20);
            __m512i v21 = _mm512_load_si512(s+j+21);
            __m512i v22 = _mm512_load_si512(s+j+22);
            __m512i v23 = _mm512_load_si512(s+j+23);
            __m512i v24 = _mm512_load_si512(s+j+24);
            __m512i v25 = _mm512_load_si512(s+j+25);
            __m512i v26 = _mm512_load_si512(s+j+26);
            __m512i v27 = _mm512_load_si512(s+j+27);
            __m512i v28 = _mm512_load_si512(s+j+28);
            __m512i v29 = _mm512_load_si512(s+j+29);
            __m512i v30 = _mm512_load_si512(s+j+30);
            __m512i v31 = _mm512_load_si512(s+j+31);

            // Non-temporal stores - bypass cache
            _mm512_stream_si512(d+j, v0);
            _mm512_stream_si512(d+j+1, v1);
            _mm512_stream_si512(d+j+2, v2);
            _mm512_stream_si512(d+j+3, v3);
            _mm512_stream_si512(d+j+4, v4);
            _mm512_stream_si512(d+j+5, v5);
            _mm512_stream_si512(d+j+6, v6);
            _mm512_stream_si512(d+j+7, v7);
            _mm512_stream_si512(d+j+8, v8);
            _mm512_stream_si512(d+j+9, v9);
            _mm512_stream_si512(d+j+10, v10);
            _mm512_stream_si512(d+j+11, v11);
            _mm512_stream_si512(d+j+12, v12);
            _mm512_stream_si512(d+j+13, v13);
            _mm512_stream_si512(d+j+14, v14);
            _mm512_stream_si512(d+j+15, v15);
            _mm512_stream_si512(d+j+16, v16);
            _mm512_stream_si512(d+j+17, v17);
            _mm512_stream_si512(d+j+18, v18);
            _mm512_stream_si512(d+j+19, v19);
            _mm512_stream_si512(d+j+20, v20);
            _mm512_stream_si512(d+j+21, v21);
            _mm512_stream_si512(d+j+22, v22);
            _mm512_stream_si512(d+j+23, v23);
            _mm512_stream_si512(d+j+24, v24);
            _mm512_stream_si512(d+j+25, v25);
            _mm512_stream_si512(d+j+26, v26);
            _mm512_stream_si512(d+j+27, v27);
            _mm512_stream_si512(d+j+28, v28);
            _mm512_stream_si512(d+j+29, v29);
            _mm512_stream_si512(d+j+30, v30);
            _mm512_stream_si512(d+j+31, v31);
        }
        _mm_sfence(); // Ensure NT stores complete
    }

    // Benchmark with synchronized start
    auto start = high_resolution_clock::now();

    for (size_t i = 0; i < iterations; ++i) {
        *reinterpret_cast<uint64_t*>(buf) = num_elements;
        const __m512i* s = (const __m512i*)data;
        __m512i* d = (__m512i*)(buf + 8);

        for (size_t j = 0; j < data_bytes/64; j += 32) {
            __m512i v0 = _mm512_load_si512(s+j);
            __m512i v1 = _mm512_load_si512(s+j+1);
            __m512i v2 = _mm512_load_si512(s+j+2);
            __m512i v3 = _mm512_load_si512(s+j+3);
            __m512i v4 = _mm512_load_si512(s+j+4);
            __m512i v5 = _mm512_load_si512(s+j+5);
            __m512i v6 = _mm512_load_si512(s+j+6);
            __m512i v7 = _mm512_load_si512(s+j+7);
            __m512i v8 = _mm512_load_si512(s+j+8);
            __m512i v9 = _mm512_load_si512(s+j+9);
            __m512i v10 = _mm512_load_si512(s+j+10);
            __m512i v11 = _mm512_load_si512(s+j+11);
            __m512i v12 = _mm512_load_si512(s+j+12);
            __m512i v13 = _mm512_load_si512(s+j+13);
            __m512i v14 = _mm512_load_si512(s+j+14);
            __m512i v15 = _mm512_load_si512(s+j+15);
            __m512i v16 = _mm512_load_si512(s+j+16);
            __m512i v17 = _mm512_load_si512(s+j+17);
            __m512i v18 = _mm512_load_si512(s+j+18);
            __m512i v19 = _mm512_load_si512(s+j+19);
            __m512i v20 = _mm512_load_si512(s+j+20);
            __m512i v21 = _mm512_load_si512(s+j+21);
            __m512i v22 = _mm512_load_si512(s+j+22);
            __m512i v23 = _mm512_load_si512(s+j+23);
            __m512i v24 = _mm512_load_si512(s+j+24);
            __m512i v25 = _mm512_load_si512(s+j+25);
            __m512i v26 = _mm512_load_si512(s+j+26);
            __m512i v27 = _mm512_load_si512(s+j+27);
            __m512i v28 = _mm512_load_si512(s+j+28);
            __m512i v29 = _mm512_load_si512(s+j+29);
            __m512i v30 = _mm512_load_si512(s+j+30);
            __m512i v31 = _mm512_load_si512(s+j+31);

            _mm512_stream_si512(d+j, v0);
            _mm512_stream_si512(d+j+1, v1);
            _mm512_stream_si512(d+j+2, v2);
            _mm512_stream_si512(d+j+3, v3);
            _mm512_stream_si512(d+j+4, v4);
            _mm512_stream_si512(d+j+5, v5);
            _mm512_stream_si512(d+j+6, v6);
            _mm512_stream_si512(d+j+7, v7);
            _mm512_stream_si512(d+j+8, v8);
            _mm512_stream_si512(d+j+9, v9);
            _mm512_stream_si512(d+j+10, v10);
            _mm512_stream_si512(d+j+11, v11);
            _mm512_stream_si512(d+j+12, v12);
            _mm512_stream_si512(d+j+13, v13);
            _mm512_stream_si512(d+j+14, v14);
            _mm512_stream_si512(d+j+15, v15);
            _mm512_stream_si512(d+j+16, v16);
            _mm512_stream_si512(d+j+17, v17);
            _mm512_stream_si512(d+j+18, v18);
            _mm512_stream_si512(d+j+19, v19);
            _mm512_stream_si512(d+j+20, v20);
            _mm512_stream_si512(d+j+21, v21);
            _mm512_stream_si512(d+j+22, v22);
            _mm512_stream_si512(d+j+23, v23);
            _mm512_stream_si512(d+j+24, v24);
            _mm512_stream_si512(d+j+25, v25);
            _mm512_stream_si512(d+j+26, v26);
            _mm512_stream_si512(d+j+27, v27);
            _mm512_stream_si512(d+j+28, v28);
            _mm512_stream_si512(d+j+29, v29);
            _mm512_stream_si512(d+j+30, v30);
            _mm512_stream_si512(d+j+31, v31);
        }
        _mm_sfence();
    }

    auto end = high_resolution_clock::now();

    double ns_per_op = duration_cast<nanoseconds>(end - start).count() / static_cast<double>(iterations);

    // Prevent optimization
    volatile uint8_t sink = buf[0];
    (void)sink;

    free(data);
    free(buf);

    // Store result
    result->gbps = data_bytes / ns_per_op;
    result->operations = iterations;
}

int main() {
    const int num_threads = std::thread::hardware_concurrency(); // Use all threads

    std::cout << "\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n";
    std::cout << "  üöÄ HARDWARE MAXIMUM - Multi-threaded Parallel Benchmark\n";
    std::cout << "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n";
    std::cout << "CPU: AMD Ryzen 9 8945HS (Zen 4)\n";
    std::cout << "Threads: " << num_threads << " (all cores + SMT)\n";
    std::cout << "Turbo Max: 332.8 GB/s (@ 5.2 GHz peak)\n";
    std::cout << "Realistic Max: 288 GB/s (@ 4.5 GHz sustained)\n\n";
    std::cout << "üéØ TARGET: 299+ GB/s (90% of TURBO MAX)\n\n";

    std::cout << "| Size | Single Thread | All Threads | Speedup | % of Turbo (332.8 GB/s) | Status |\n";
    std::cout << "|------|---------------|-------------|---------|-------------------------|--------|\n";

    struct TestConfig {
        size_t num_elements;
        const char* name;
        size_t iterations;
    };

    std::vector<TestConfig> configs = {
        {128, "1KB", 1000},
        {256, "2KB", 500},
        {512, "4KB", 250},
        {1024, "8KB", 100},
        {2048, "16KB", 50},
        {4096, "32KB", 25},
    };

    for (const auto& cfg : configs) {
        // Must be multiple of 2048 bytes for 32x unrolling
        if ((cfg.num_elements * 8) % 2048 != 0) continue;

        // Single-threaded baseline
        ThreadResult baseline_result;
        thread_benchmark(0, cfg.num_elements, cfg.iterations, &baseline_result);

        // Multi-threaded test
        std::vector<std::thread> threads;
        std::vector<ThreadResult> results(num_threads);

        ready_count = 0;
        start_flag = false;

        // Launch all threads
        for (int i = 0; i < num_threads; ++i) {
            threads.emplace_back(thread_benchmark, i, cfg.num_elements, cfg.iterations, &results[i]);
        }

        // Wait for all threads to be ready
        while (ready_count.load() < num_threads) {
            std::this_thread::sleep_for(std::chrono::microseconds(10));
        }

        // Start all threads simultaneously
        start_flag.store(true, std::memory_order_release);

        // Wait for completion
        for (auto& t : threads) {
            t.join();
        }

        // Aggregate results
        double total_gbps = 0;
        for (const auto& r : results) {
            total_gbps += r.gbps;
        }

        double speedup = total_gbps / baseline_result.gbps;
        double percent_of_max = (total_gbps / 332.8) * 100.0; // % of TURBO MAX

        const char* status;
        if (percent_of_max >= 90.0) status = "üèÜ GOAL!";
        else if (percent_of_max >= 80.0) status = "‚úÖ Excellent";
        else if (percent_of_max >= 70.0) status = "‚úÖ Great";
        else if (percent_of_max >= 60.0) status = "‚ö†Ô∏è Good";
        else status = "‚ö†Ô∏è Optimize";

        std::cout << "| " << std::setw(4) << cfg.name
                  << " | " << std::fixed << std::setprecision(2) << std::setw(10) << baseline_result.gbps << " GB/s"
                  << " | **" << std::setw(8) << total_gbps << " GB/s** | "
                  << std::setw(5) << speedup << "x | "
                  << std::setw(6) << std::setprecision(1) << percent_of_max << "% | "
                  << status << " |\n";
        std::cout.flush();
    }

    std::cout << "\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n";
    std::cout << "  Optimizations:\n";
    std::cout << "  ‚úÖ Multi-threaded (" << num_threads << " threads)\n";
    std::cout << "  ‚úÖ 32x loop unrolling (2048 bytes/iteration)\n";
    std::cout << "  ‚úÖ Non-temporal stores (_mm512_stream_si512)\n";
    std::cout << "  ‚úÖ Synchronized parallel execution\n";
    std::cout << "  ‚úÖ Per-thread buffers (no contention)\n";
    std::cout << "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n";

    return 0;
}
